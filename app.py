# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xA19vtmaodF_kscz0dQecgsKsmYX_lvo
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import os, glob, json, joblib
# import numpy as np
# import pandas as pd
# import streamlit as st
# import matplotlib.pyplot as plt
# 
# # =========================
# # CONFIG
# # =========================
# OUT_DIR = "/content/drive/MyDrive/Colab Notebooks/hotel_cancellation_outputs"
# FEAT_PATH = os.path.join(OUT_DIR, "Exp4_feature_cols.json")
# 
# # Priority order for tuned model (based on your tuning outcome)
# PREFERRED_TUNED = [
#     "Exp4_TUNED_XGBoost.pkl",
#     "Exp4_TUNED_RandomForest.pkl",
#     "Exp4_TUNED_DecisionTree.pkl",
#     "Exp4_TUNED_SVM.pkl",
# ]
# 
# # =========================
# # Helpers
# # =========================
# def auto_find_model(out_dir: str) -> str:
#     # 1) Preferred tuned models
#     for fn in PREFERRED_TUNED:
#         p = os.path.join(out_dir, fn)
#         if os.path.exists(p):
#             return p
# 
#     # 2) Any Exp4_TUNED_*.pkl
#     tuned_any = sorted(glob.glob(os.path.join(out_dir, "Exp4_TUNED_*.pkl")))
#     if tuned_any:
#         return tuned_any[0]
# 
#     # 3) Any .pkl
#     any_pkl = sorted(glob.glob(os.path.join(out_dir, "*.pkl")))
#     if any_pkl:
#         return any_pkl[0]
# 
#     return None
# 
# @st.cache_resource
# def load_model_and_features():
#     if not os.path.exists(FEAT_PATH):
#         raise FileNotFoundError(f"Missing feature file: {FEAT_PATH}")
# 
#     with open(FEAT_PATH, "r", encoding="utf-8") as f:
#         feature_cols = json.load(f)
# 
#     model_path = auto_find_model(OUT_DIR)
#     if model_path is None or (not os.path.exists(model_path)):
#         raise FileNotFoundError(f"No model .pkl found in: {OUT_DIR}")
# 
#     model = joblib.load(model_path)
#     return model, feature_cols, model_path
# 
# def align_input_df(df_in: pd.DataFrame, feature_cols: list):
#     df = df_in.copy()
#     # add missing cols
#     missing = [c for c in feature_cols if c not in df.columns]
#     for c in missing:
#         df[c] = np.nan
#     # drop extra cols
#     extras = [c for c in df.columns if c not in feature_cols]
#     if extras:
#         df = df.drop(columns=extras)
#     # reorder
#     df = df[feature_cols]
#     return df, missing, extras
# 
# def predict_df(model, df_aligned: pd.DataFrame):
#     pred = model.predict(df_aligned)
#     proba = None
#     if hasattr(model, "predict_proba"):
#         proba = model.predict_proba(df_aligned)[:, 1]
#     return pred, proba
# 
# def build_template_csv(feature_cols: list) -> pd.DataFrame:
#     return pd.DataFrame(columns=feature_cols)
# 
# # =========================
# # UI Dictionaries (Exp4 feature set based on your screenshot)
# # If a feature is not in FEATURE_COLS, it will be ignored automatically.
# # =========================
# CATEGORICAL_OPTIONS = {
#     "deposit_type": ["No Deposit", "Non Refund", "Refundable"],
#     "market_segment": ["Direct", "Corporate", "Online TA", "Offline TA/TO", "Groups", "Complementary", "Aviation"],
#     "arrival_date_month": ["January","February","March","April","May","June","July","August","September","October","November","December"],
#     "country": ["PRT", "GBR", "ESP", "FRA", "DEU", "IRL", "ITA", "NLD", "BEL", "BRA", "USA", "Other"],
#     "reserved_room_type": ["A","B","C","D","E","F","G","H","L","P"],
#     "assigned_room_type": ["A","B","C","D","E","F","G","H","I","K","L","P"],
#     "customer_type": ["Transient", "Transient-Party", "Contract", "Group"],
#     "distribution_channel": ["Direct", "Corporate", "TA/TO", "GDS"],
# }
# 
# NUMERIC_HINTS = {
#     "total_of_special_requests": (0, 5, 0),
#     "arrival_date_week_number": (1, 53, 1),
#     "arrival_date_day_of_month": (1, 31, 1),
#     "res_status_year": (2014, 2026, 2017),
# }
# 
# def render_value_input(feat: str):
#     """
#     - If feat has options -> dropdown + optional custom text if 'Other'
#     - Else -> text input (auto convert to float if possible)
#     """
#     if feat in CATEGORICAL_OPTIONS:
#         opts = CATEGORICAL_OPTIONS[feat]
#         choice = st.selectbox(feat, ["(blank)"] + opts, index=0)
#         if choice == "(blank)":
#             return np.nan
#         if choice == "Other":
#             custom = st.text_input(f"{feat} (custom value)", value="")
#             return custom.strip() if custom.strip() else np.nan
#         return choice
# 
#     if feat in NUMERIC_HINTS:
#         mn, mx, default = NUMERIC_HINTS[feat]
#         return st.number_input(feat, min_value=mn, max_value=mx, value=default, step=1)
# 
#     # fallback
#     raw = st.text_input(feat, value="")
#     if raw.strip() == "":
#         return np.nan
#     try:
#         return float(raw)
#     except:
#         return raw
# 
# # =========================
# # PAGE
# # =========================
# st.set_page_config(page_title="Hotel Booking Cancellation Prediction", layout="wide")
# 
# st.title("üè® Hotel Booking Cancellation Prediction System")
# st.caption("Predict hotel booking cancellations using Machine Learning.")
# 
# try:
#     model, FEATURE_COLS, MODEL_PATH = load_model_and_features()
# except Exception as e:
#     st.error(str(e))
#     st.stop()
# 
# st.write(f"**Model Used:** `{os.path.basename(MODEL_PATH)}`")
# #st.write(f"**Using features:** {len(FEATURE_COLS)} columns")
# 
# tab1, tab2 = st.tabs(["üßç Individual Prediction", "üìä Batch Prediction & Trend"])
# 
# # =========================
# # TAB 1: Individual
# # =========================
# with tab1:
#     st.subheader("Individual Booking Prediction")
# 
#     THRESHOLD_HIGH = 0.30  # 30% high-risk threshold
# 
#     mode = st.radio("Choose input mode:", ["Manual Form", "Upload 1-row CSV"], horizontal=True)
# 
#     # -------------------------
#     # MODE 1: Manual Form
#     # -------------------------
#     if mode == "Manual Form":
#         st.info("Dropdowns for categorical fields. Numeric fields use number input. You may leave blank if unknown.")
# 
#         row = {}
#         cols_per_row = 3
#         chunks = [FEATURE_COLS[i:i+cols_per_row] for i in range(0, len(FEATURE_COLS), cols_per_row)]
# 
#         for chunk in chunks:
#             cols = st.columns(cols_per_row)
#             for i, feat in enumerate(chunk):
#                 with cols[i]:
#                     row[feat] = render_value_input(feat)  # <- your helper
# 
#         if st.button("Predict (Individual) ‚úÖ"):
#             df_one = pd.DataFrame([row])
#             df_one, missing, extras = align_input_df(df_one, FEATURE_COLS)
# 
#             pred, proba = predict_df(model, df_one)
# 
#             # probability handling
#             prob = float(proba[0]) if proba is not None else None
# 
#             # risk label (based on probability)
#             if prob is not None:
#                 prob_percent = prob * 100
#                 if prob >= THRESHOLD_HIGH:
#                     st.error("üî¥ High Risk Booking")
#                 else:
#                     st.success("üü¢ Low Risk Booking")
#                 st.write(f"Cancellation Probability: **{prob_percent:.2f}%**")
#             else:
#                 st.info("Model does not provide probability output (predict_proba not available).")
# 
#             # optional: show class prediction also (but don't use it for risk)
#             label = "Canceled ‚ùå" if int(pred[0]) == 1 else "Not Canceled ‚úÖ"
#             st.write(f"Class Prediction: **{label}**")
# 
#             with st.expander("Show aligned row used for prediction"):
#                 st.dataframe(df_one)
# 
#     # -------------------------
#     # MODE 2: Upload 1-row CSV
#     # -------------------------
#     else:
#         st.info("Upload a CSV with **exactly 1 row**. Columns can be partial; missing columns will be auto-filled as NaN.")
#         uploaded = st.file_uploader("Upload 1-row CSV", type=["csv"])
# 
#         st.download_button(
#             "Download Template CSV (columns only)",
#             data=build_template_csv(FEATURE_COLS).to_csv(index=False).encode("utf-8"),
#             file_name="individual_template.csv",
#             mime="text/csv"
#         )
# 
#         if uploaded is not None:
#             df_up = pd.read_csv(uploaded)
# 
#             if len(df_up) != 1:
#                 st.error(f"Your file has {len(df_up)} rows. For Individual tab, upload exactly 1 row.")
#             else:
#                 df_aligned, missing, extras = align_input_df(df_up, FEATURE_COLS)
# 
#                 if missing:
#                     st.warning(f"Missing columns auto-added as NaN: {missing}")
#                 if extras:
#                     st.warning(f"Extra columns ignored: {extras}")
# 
#                 if st.button("Predict (Uploaded 1-row) ‚úÖ"):
#                     pred, proba = predict_df(model, df_aligned)
# 
#                     prob = float(proba[0]) if proba is not None else None
# 
#                     # risk label (based on probability)
#                     if prob is not None:
#                         prob_percent = prob * 100
#                         if prob >= THRESHOLD_HIGH:
#                             st.error("üî¥ High Risk Booking")
#                         else:
#                             st.success("üü¢ Low Risk Booking")
#                         st.write(f"Cancellation Probability: **{prob_percent:.2f}%**")
#                     else:
#                         st.info("Model does not provide probability output (predict_proba not available).")
# 
#                     # optional: show class prediction also
#                     label = "Canceled ‚ùå" if int(pred[0]) == 1 else "Not Canceled ‚úÖ"
#                     st.write(f"Class Prediction: **{label}**")
# 
#                     with st.expander("Show aligned row used for prediction"):
#                         st.dataframe(df_aligned)
# 
# # =========================
# # TAB 2: Batch Prediction & Trend  (FIXED + COMPLETE)
# # - fixed category dropdown (can switch category after prediction)
# # - batch limit = 200 rows (auto take first 200, no slider, no extra printing)
# # - includes: Preview table, Risk buckets, Top 10 highest-risk, Monthly trend, Category chart, Download
# # =========================
# with tab2:
#     st.subheader("üìä Batch Prediction & Trend")
#     st.info("Upload CSV (batch). Columns can be partial; missing columns will be auto-filled as NaN.")
# 
#     uploaded2 = st.file_uploader("Upload Batch CSV", type=["csv"], key="batch_csv")
# 
#     st.download_button(
#         "Download Template CSV (for batch)",
#         data=build_template_csv(FEATURE_COLS).to_csv(index=False).encode("utf-8"),
#         file_name="batch_template.csv",
#         mime="text/csv"
#     )
# 
#     # ---------- helpers (keep inside tab2; uses existing FEATURE_COLS) ----------
#     MONTH_MAP = {
#         "January":1, "February":2, "March":3, "April":4, "May":5, "June":6,
#         "July":7, "August":8, "September":9, "October":10, "November":11, "December":12,
#         "Jan":1, "Feb":2, "Mar":3, "Apr":4, "Jun":6, "Jul":7, "Aug":8, "Sep":9, "Oct":10, "Nov":11, "Dec":12
#     }
# 
#     def build_month_index(df_):
#         """
#         Build month_index = YYYY-MM-01 using arrival_date_month + (res_status_year OR arrival_date_year).
#         Returns df with month_index column, or None if cannot build.
#         """
#         df_ = df_.copy()
# 
#         if "arrival_date_month" not in df_.columns:
#             return None
# 
#         # month
#         df_["arrival_date_month"] = df_["arrival_date_month"].astype(str)
#         df_["_month_num"] = df_["arrival_date_month"].map(MONTH_MAP)
# 
#         # year column
#         year_col = None
#         for cand in ["res_status_year", "arrival_date_year"]:
#             if cand in df_.columns:
#                 year_col = cand
#                 break
#         if year_col is None:
#             return None
# 
#         df_["_year_num"] = pd.to_numeric(df_[year_col], errors="coerce")
# 
#         df_ = df_.dropna(subset=["_month_num", "_year_num"]).copy()
#         if df_.empty:
#             return None
# 
#         df_["_month_num"] = df_["_month_num"].astype(int)
#         df_["_year_num"] = df_["_year_num"].astype(int)
# 
#         df_["month_index"] = pd.to_datetime(
#             dict(year=df_["_year_num"], month=df_["_month_num"], day=1),
#             errors="coerce"
#         )
#         df_ = df_.dropna(subset=["month_index"]).copy()
#         if df_.empty:
#             return None
# 
#         return df_
# 
#     # ---------- persist results so dropdown can change without re-clicking predict ----------
#     if "batch_df_out" not in st.session_state:
#         st.session_state["batch_df_out"] = None
# 
#     THRESHOLD_HIGH = 0.30  # keep same logic
#     BATCH_LIMIT = 200      # per your requirement
# 
#     if uploaded2 is not None:
#         df_up = pd.read_csv(uploaded2)
#         df_aligned, missing, extras = align_input_df(df_up, FEATURE_COLS)
# 
#         # hard limit: accept only first 200
#         df_aligned = df_aligned.head(BATCH_LIMIT).copy()
# 
#         # (optional) keep warnings minimal; comment out if you hate warnings
#         if missing:
#             st.warning(f"Missing columns auto-added as NaN: {missing}")
#         if extras:
#             st.warning(f"Extra columns ignored: {extras}")
# 
#         if st.button("Predict (Batch) ‚úÖ", key="predict_batch"):
#             pred, proba = predict_df(model, df_aligned)
# 
#             df_out = df_aligned.copy()
#             df_out["predicted_cancel"] = pred.astype(int)
# 
#             if proba is not None:
#                 df_out["cancel_probability"] = proba.astype(float)  # 0-1
#                 df_out["cancel_probability_pct"] = (df_out["cancel_probability"] * 100).round(2)
#             else:
#                 df_out["cancel_probability"] = np.nan
#                 df_out["cancel_probability_pct"] = np.nan
# 
#             df_out["risk_label"] = np.where(
#                 df_out["cancel_probability"].fillna(0) >= THRESHOLD_HIGH,
#                 "High Risk",
#                 "Low Risk"
#             )
# 
#             st.session_state["batch_df_out"] = df_out
#             st.success("Batch prediction completed (processed 200 rows max).")
# 
#     # ---------- render outputs if prediction exists ----------
#     df_out = st.session_state.get("batch_df_out", None)
# 
#     if df_out is not None:
#         # =========================
#         # KPI SUMMARY
#         # =========================
#         st.markdown("## Batch Summary")
#         c1, c2, c3 = st.columns(3)
# 
#         c1.metric("Total bookings", f"{len(df_out):,}")
#         if df_out["cancel_probability"].notna().any():
#             c2.metric("Avg cancel probability", f"{df_out['cancel_probability'].mean()*100:.2f}%")
#         else:
#             c2.metric("Avg cancel probability", "N/A")
#         c3.metric("Predicted cancel rate", f"{df_out['predicted_cancel'].mean()*100:.2f}%")
# 
#         # =========================
#         # 1) PREVIEW TABLE (Top 30)
#         # =========================
#         st.markdown("### üîé Preview (Top 30 rows)")
#         show_cols = [c for c in FEATURE_COLS if c in df_out.columns] + [
#             "predicted_cancel", "cancel_probability_pct", "risk_label"
#         ]
#         st.dataframe(df_out[show_cols].head(30), use_container_width=True)
# 
#         # =========================
#         # 2) MONTHLY TREND
#         # =========================
#         st.markdown("### üìà Monthly Trend (Risk, Cancel Rate, and Volume)")
# 
#         df_m = build_month_index(df_out)
# 
#         if df_m is None:
#             st.warning("Trend chart skipped: need 'arrival_date_month' + ('res_status_year' or 'arrival_date_year') in uploaded batch.")
#         else:
#             trend = (
#                 df_m.groupby("month_index", as_index=False)
#                 .agg(
#                     bookings=("predicted_cancel", "size"),
#                     avg_cancel_prob=("cancel_probability", "mean"),
#                     cancel_rate=("predicted_cancel", "mean"),
#                 )
#                 .sort_values("month_index")
#             )
# 
#             # Convert to %
#             trend["Avg Cancel Probability (%)"] = (trend["avg_cancel_prob"] * 100).round(2)
#             trend["Predicted Cancel Rate (%)"]  = (trend["cancel_rate"] * 100).round(2)
#             trend["Bookings"] = trend["bookings"].astype(int)
# 
#             # ‚úÖ Make categorical month labels (so it won't stretch like timeline)
#             trend["Month"] = trend["month_index"].dt.strftime("%b %Y")
#             month_order = trend["Month"].tolist()  # keep correct order
# 
#             # Optional: show quick note if too few months
#             if len(trend) < 3:
#                 st.info(f"Only **{len(trend)} month(s)** detected in this batch file. Trend line may look flat because there are few points.")
# 
#             st.caption(
#                 "‚Ä¢ **Avg Cancel Probability (%)** = average risk score predicted by the model.\n"
#                 "‚Ä¢ **Predicted Cancel Rate (%)** = % bookings predicted as cancel (based on threshold).\n"
#                 "‚Ä¢ **Bookings** = number of records in that month (volume)."
#             )
# 
#             # --- Line chart (categorical x-axis)
#             line_df = trend.set_index("Month")[["Avg Cancel Probability (%)", "Predicted Cancel Rate (%)"]]
#             # keep correct order (important if Streamlit reorders)
#             line_df = line_df.reindex(month_order)
#             st.line_chart(line_df, height=300)
# 
#             # --- Bar chart (volume) categorical x-axis
#             vol_df = trend.set_index("Month")[["Bookings"]].reindex(month_order)
#             st.bar_chart(vol_df, height=200)
# 
#             with st.expander("Show monthly trend table"):
#                 st.dataframe(
#                     trend[["Month", "Bookings", "Avg Cancel Probability (%)", "Predicted Cancel Rate (%)"]],
#                     use_container_width=True
#                 )
# 
#         # =========================
#         # 3) RISK DISTRIBUTION (STREAMLIT STYLE)
#         # =========================
#         st.markdown("### üìä Risk Distribution (Probability Ranges)")
#         st.caption(
#             "This chart groups bookings into **risk ranges** based on predicted cancellation probability.\n"
#             "Example: **70‚Äì100%** = very high cancellation risk."
#         )
# 
#         if df_out["cancel_probability"].notna().any():
#             bins = [0, 0.10, 0.20, 0.30, 0.50, 0.70, 1.00]
#             labels = ["0‚Äì10%", "10‚Äì20%", "20‚Äì30%", "30‚Äì50%", "50‚Äì70%", "70‚Äì100%"]
# 
#             bucket = pd.cut(df_out["cancel_probability"], bins=bins, labels=labels, include_lowest=True)
#             bucket_counts = bucket.value_counts().reindex(labels).fillna(0).astype(int)
# 
#             # Streamlit bar_chart wants a dataframe/series
#             bucket_df = pd.DataFrame({"Bookings": bucket_counts.values}, index=labels)
#             st.bar_chart(bucket_df, height=260)
# 
#             with st.expander("Show bucket breakdown table"):
#                 bucket_pct = (bucket_counts / bucket_counts.sum() * 100).round(2)
#                 st.dataframe(
#                     pd.DataFrame({
#                         "Risk Range": labels,
#                         "Count": bucket_counts.values,
#                         "Percentage (%)": bucket_pct.values
#                     }),
#                     use_container_width=True
#                 )
#         else:
#             st.info("No probability output available for this model (predict_proba not supported).")
# 
# 
#         # =========================
#         # 4) TOP 10 HIGHEST-RISK
#         # =========================
#         st.markdown("### üî• Top 10 Highest-Risk Bookings")
#         if df_out["cancel_probability"].notna().any():
#             top_risk = df_out.sort_values("cancel_probability", ascending=False).head(10).copy()
#             cols_keep = [c for c in FEATURE_COLS if c in top_risk.columns] + [
#                 "cancel_probability_pct", "risk_label"
#             ]
#             st.dataframe(top_risk[cols_keep], use_container_width=True)
#         else:
#             st.info("Top-risk table skipped (no probabilities).")
# 
#         # =========================
#         # 5) RISK BY CATEGORY (DROPDOWN FIXED)
#         # =========================
#         st.markdown("### üß© Risk by Category (Avg Probability %)")
#         cat_candidates = [
#             "market_segment", "country", "distribution_channel",
#             "customer_type", "deposit_type", "assigned_room_type", "reserved_room_type"
#         ]
#         available_cats = [c for c in cat_candidates if c in df_out.columns]
# 
#         if df_out["cancel_probability"].notna().any() and len(available_cats) > 0:
#             picked_cat = st.selectbox(
#                 "Pick a category:",
#                 available_cats,
#                 index=0,
#                 key="cat_pick_batch"  # stable key so it updates
#             )
# 
#             cat_summary = (
#                 df_out.groupby(picked_cat, as_index=False)["cancel_probability"]
#                 .mean()
#                 .sort_values("cancel_probability", ascending=False)
#                 .head(10)
#             )
#             cat_summary["avg_cancel_probability_pct"] = (cat_summary["cancel_probability"] * 100).round(2)
# 
#             # nicer like before (streamlit bar_chart)
#             st.bar_chart(
#                 cat_summary.set_index(picked_cat)[["avg_cancel_probability_pct"]],
#                 height=260
#             )
#         else:
#             st.info("Category analysis skipped (need probability + at least 1 categorical column present).")
# 
#         # =========================
#         # 6) DOWNLOAD OUTPUT CSV
#         # =========================
#         st.download_button(
#             "‚¨á Download Predictions CSV",
#             data=df_out.to_csv(index=False).encode("utf-8"),
#             file_name="batch_predictions.csv",
#             mime="text/csv"
#         )
#